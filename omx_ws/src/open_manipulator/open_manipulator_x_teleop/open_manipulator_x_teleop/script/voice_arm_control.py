from vosk import Model, KaldiRecognizer
import sounddevice as sd
import json
import rclpy
from rclpy.node import Node
from open_manipulator_msgs.srv import SetJointPosition
from sensor_msgs.msg import JointState

# --- åˆå§‹åŒ–åƒæ•¸ ---
goal_joint_angle = [0.0, 0.0, 0.0, 0.0]
goal_tool_angle = [0.0]

# --- èªéŸ³è¾¨è­˜æ¨¡å‹ ---
model = Model("/home/yuzhe/vosk_models/model-cn")
recognizer = KaldiRecognizer(model, 16000)
recognizer.SetWords(False)

# --- ROS2 ç¯€é» ---
class VoiceArmControl(Node):
    def __init__(self):
        super().__init__('voice_arm_control')
        self.tool_client = self.create_client(SetJointPosition, 'goal_tool_control')
        self.joint_client = self.create_client(SetJointPosition, 'goal_joint_space_path')
        self.joint_sub = self.create_subscription(JointState, 'joint_states', self.joint_callback, 10)

    def joint_callback(self, msg):
        for i in range(4):
            goal_joint_angle[i] = msg.position[i]

    def send_joint(self, angles):
        req = SetJointPosition.Request()
        req.joint_position.joint_name = ['joint1', 'joint2', 'joint3', 'joint4']
        req.joint_position.position = angles
        req.path_time = 1.0
        self.joint_client.call_async(req)

    def send_gripper(self, val):
        req = SetJointPosition.Request()
        req.joint_position.joint_name = ['gripper']
        req.joint_position.position = [val]
        req.path_time = 1.0
        self.tool_client.call_async(req)

def listen_and_control(node):
    def callback(indata, frames, time, status):
        if recognizer.AcceptWaveform(bytes(indata)):
            result = json.loads(recognizer.Result())
            text = result.get("text", "")
            print(f"ğŸ¤ è¾¨è­˜ï¼š{text}")

            if "å®¶" in text:
                print("â†’ èªéŸ³ï¼šå®¶ â†’ åŸ·è¡Œå¤¾å–")
                node.send_joint([-0.230097, 0.817612, -0.503146, 1.256330])
                node.send_gripper(-0.01)
            elif "æ”¶" in text:
                print("â†’ èªéŸ³ï¼šæ”¶ â†’ åŸ·è¡Œæ”¶å›")
                node.send_joint([-0.081301, -1.038505, 0.684155, 1.402058])
            elif "æ”¾" in text:
                print("â†’ èªéŸ³ï¼šæ”¾ â†’ æ”¾é–‹")
                node.send_gripper(0.0)
            elif "åˆå§‹åŒ–" in text or "æ­¸ä½" in text:
                print("â†’ èªéŸ³ï¼šåˆå§‹åŒ–")
                node.send_joint([-0.230097, 0.817612, -0.503146, 1.256330])
    
    stream = sd.InputStream(samplerate=16000, blocksize=8000, dtype='int16', channels=1, callback=callback)
    with stream:
        print("ğŸŸ¢ èªéŸ³æ§åˆ¶å•Ÿå‹•ä¸­ï¼šè«‹èªªã€å®¶ã€ã€ã€æ”¶ã€ã€ã€æ”¾ã€ã€ã€åˆå§‹åŒ–ã€")
        while True:
            pass

def main():
    rclpy.init()
    node = VoiceArmControl()
    listen_and_control(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
